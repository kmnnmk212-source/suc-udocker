# -*- coding: utf-8 -*-
"""suc_udocker.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12EkRGSpR6irRZhDBiXEotc8Q7ApUSwQ3
"""





!curl -fsSL https://get.docker.com | sh

!docker

!sudo docker run --rm hello-world

!pip install udocker

!udocker install

# Commented out IPython magic to ensure Python compatibility.
# %env UDOCKER_ALLOW_ROOT=1

!udocker install

# Commented out IPython magic to ensure Python compatibility.
# %env UDOCKER_ALLOW_ROOT=1 & udocker install

!udocker --allow-root -h

!UDOCKER_ALLOW_ROOT=1 udocker install



!udocker --allow-root install

!udocker --allow-root run hello-world

!pip install udocker

"""Model
Thinking Thoughts

Expand to view model thoughts
chevron_right

ููุชุงุฒ! ุจูุง ุฃู hello-world ุงุดุชุบูุชุ ููุฐุง ูุนูู ุฃู ูุญุฑู udocker ุฌุงูุฒ ุชูุงูุงู.

ุจูุง ุฃูู ูู Google Colabุ ุงููุฏู ุบุงูุจุงู ูู ุชุดุบูู ุฃููุงุฏ ุจุงูุซูู ุฃู ุฐูุงุก ุงุตุทูุงุนู. ุฅููู ุงูุฃููุงุฏ ุงูุชุงููุฉ ูุชุจุฏุฃ ุงูุนูู ุงูุฌุงุฏ (ุงูุณุฎูุง ูุฌุฑุจูุง):
1. ุชุฌุฑุจุฉ ุจุงูุซูู ุฏุงุฎู ูููุชููุฑ (ุจุฏูู GPU)

ุจุฏูุงู ูู hello-worldุ ุฏุนูุง ูุดุบู ูุธุงู ููููุณ ูุตุบุฑ ุจุฏุงุฎูู ุจุงูุซูู:
code Bash

# ุชุญููู ูุชุดุบูู ุจุงูุซูู ูุจุงุดุฑุฉ ูุทุจุงุนุฉ ุฅุตุฏุงุฑูุง
!udocker --allow-root run python:3.9-slim python --version

2. ุชุดุบูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุน GPU (ุงูุฃูู) ๐ฅ

ูุฐู ูู ุงูุฎุทูุฉ ุงูุงุญุชุฑุงููุฉ. ุณูููู ุจุชุญููู ุตูุฑุฉ PyTorchุ ููุถุจุท ุฅุนุฏุงุฏุงุช NVIDIA ููู ุชุฑู ุงูุญุงููุฉ ูุฑุช ุงูุดุงุดุฉ ุงูุฎุงุต ุจุฌูุฌู ูููุงุจ.

ููุฐ ูุฐู ุงูุฃูุงูุฑ ูู ุฎููุฉ ุฌุฏูุฏุฉ ุจุงูุชุฑุชูุจ:
code Bash

# 1. ุณุญุจ ุตูุฑุฉ PyTorch (ุญุฌููุง ูุจูุฑ ููููุงู)
!udocker --allow-root pull pytorch/pytorch:latest

# 2. ุฅูุดุงุก ุงูุญุงููุฉ ูุชุณููุชูุง "my_ai" (ุจุฏูู ุชุดุบูููุง ุจุนุฏ)
!udocker --allow-root create --name=my_ai pytorch/pytorch:latest

# 3. โ๏ธ ุงูุฎุทูุฉ ุงูุณุญุฑูุฉ: ูุณุฎ ุชุนุฑููุงุช ูุฑุช ุงูุดุงุดุฉ ูุฏุงุฎู ุงูุญุงููุฉ
!udocker --allow-root setup --nvidia my_ai

# 4. ุชุดุบูู ุงุฎุชุจุงุฑ ููุชุฃูุฏ ุฃู ุงููุฑุช ูุนูู
!udocker --allow-root run my_ai python -c "import torch; print('GPU Name:', torch.cuda.get_device_name(0))"

ุฅุฐุง ุทุจุน ูู ุงุณู ุงููุฑุช (ูุซูุงู Tesla T4)ุ ูุฃูุช ูุฌุญุช ูู ุชุดุบูู Docker ูุน GPU ุฏุงุฎู Colab!
3. ููู ุชุตู ููููุงุชู ุฏุงุฎู ุงููููุชููุฑุ

ุฅุฐุง ูุงู ูุฏูู ููุฏ ุฃู ุฏุงุชุง (Data) ูู ูููุงุช Colab ูุชุฑูุฏ ูููููุชููุฑ ุฃู ูุฑุงูุงุ ุงุณุชุฎุฏู ุฎูุงุฑ --volume.

ูุซุงู:
code Bash

# ูุฐุง ุงูุฃูุฑ ูุฌุนู ุงููุฌูุฏ ุงูุญุงูู (.) ูู ูููุงุจ ุธุงูุฑุงู ุฏุงุฎู ุงููููุชููุฑ ูู ูุณุงุฑ /data
!udocker --allow-root run --volume=$(pwd):/data my_ai ls /data

info Google AI models may make mistakes, so double-check outputs.
Use Arrow Up and Arrow Down to select a turn, Enter to jump to it, and Escape to return to the chat.
google Grounding with Google Search

"""

!udocker --allow-root run --volume=$(pwd):/data my_ai ls /data

/content/sample_data

!udocker --allow-root run --volume=$(pwd):/sample_data my_ai ls /sample_data

# Commented out IPython magic to ensure Python compatibility.
# %cd /root/.udocker

!ls

!udocker --allow-root run --volume=$(pwd):/bin my_ai ls /bin

!udocker --allow-root pull python:3.9-slim

!udocker --allow-root create --name=my_lab python:3.9-slim

# ุชุซุจูุช ููุชุจุฉ numpy ุฏุงุฎู ุงูุญุงููุฉ
!udocker --allow-root run my_lab pip install numpy

# ุชุดุบูู ููุฏ ุจุงูุซูู ุฏุงุฎู ุงูุญุงููุฉ
!udocker --allow-root run my_lab python -c "import numpy; print('Numpy Version inside container:', numpy.__version__)"

!udocker --allow-root run my_lab sh -c "pip install pandas && python -c 'import pandas; print(pandas.__version__)'"

!udocker --allow-root run my_lab python --version

!udocker --allow-root run my_lab pip show numpy

!udocker --allow-root run my_lab python -c "import numpy; print(numpy.__version__)"

!udocker --allow-root run my_lab pip list





"""ููุชุงุฒ! ุจูุง ุฃู hello-world ุงุดุชุบูุชุ ููุฐุง ูุนูู ุฃู ูุญุฑู udocker ุฌุงูุฒ ุชูุงูุงู.

ุจูุง ุฃูู ูู Google Colabุ ุงููุฏู ุบุงูุจุงู ูู ุชุดุบูู ุฃููุงุฏ ุจุงูุซูู ุฃู ุฐูุงุก ุงุตุทูุงุนู. ุฅููู ุงูุฃููุงุฏ ุงูุชุงููุฉ ูุชุจุฏุฃ ุงูุนูู ุงูุฌุงุฏ (ุงูุณุฎูุง ูุฌุฑุจูุง):
1. ุชุฌุฑุจุฉ ุจุงูุซูู ุฏุงุฎู ูููุชููุฑ (ุจุฏูู GPU)

ุจุฏูุงู ูู hello-worldุ ุฏุนูุง ูุดุบู ูุธุงู ููููุณ ูุตุบุฑ ุจุฏุงุฎูู ุจุงูุซูู:
code Bash

# ุชุญููู ูุชุดุบูู ุจุงูุซูู ูุจุงุดุฑุฉ ูุทุจุงุนุฉ ุฅุตุฏุงุฑูุง
!udocker --allow-root run python:3.9-slim python --version

2. ุชุดุบูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุน GPU (ุงูุฃูู) ๐ฅ

ูุฐู ูู ุงูุฎุทูุฉ ุงูุงุญุชุฑุงููุฉ. ุณูููู ุจุชุญููู ุตูุฑุฉ PyTorchุ ููุถุจุท ุฅุนุฏุงุฏุงุช NVIDIA ููู ุชุฑู ุงูุญุงููุฉ ูุฑุช ุงูุดุงุดุฉ ุงูุฎุงุต ุจุฌูุฌู ูููุงุจ.

ููุฐ ูุฐู ุงูุฃูุงูุฑ ูู ุฎููุฉ ุฌุฏูุฏุฉ ุจุงูุชุฑุชูุจ:
code Bash

# 1. ุณุญุจ ุตูุฑุฉ PyTorch (ุญุฌููุง ูุจูุฑ ููููุงู)
!udocker --allow-root pull pytorch/pytorch:latest

# 2. ุฅูุดุงุก ุงูุญุงููุฉ ูุชุณููุชูุง "my_ai" (ุจุฏูู ุชุดุบูููุง ุจุนุฏ)
!udocker --allow-root create --name=my_ai pytorch/pytorch:latest

# 3. โ๏ธ ุงูุฎุทูุฉ ุงูุณุญุฑูุฉ: ูุณุฎ ุชุนุฑููุงุช ูุฑุช ุงูุดุงุดุฉ ูุฏุงุฎู ุงูุญุงููุฉ
!udocker --allow-root setup --nvidia my_ai

# 4. ุชุดุบูู ุงุฎุชุจุงุฑ ููุชุฃูุฏ ุฃู ุงููุฑุช ูุนูู
!udocker --allow-root run my_ai python -c "import torch; print('GPU Name:', torch.cuda.get_device_name(0))"

ุฅุฐุง ุทุจุน ูู ุงุณู ุงููุฑุช (ูุซูุงู Tesla T4)ุ ูุฃูุช ูุฌุญุช ูู ุชุดุบูู Docker ูุน GPU ุฏุงุฎู Colab!
3. ููู ุชุตู ููููุงุชู ุฏุงุฎู ุงููููุชููุฑุ

ุฅุฐุง ูุงู ูุฏูู ููุฏ ุฃู ุฏุงุชุง (Data) ูู ูููุงุช Colab ูุชุฑูุฏ ูููููุชููุฑ ุฃู ูุฑุงูุงุ ุงุณุชุฎุฏู ุฎูุงุฑ --volume.

ูุซุงู:
code Bash

# ูุฐุง ุงูุฃูุฑ ูุฌุนู ุงููุฌูุฏ ุงูุญุงูู (.) ูู ูููุงุจ ุธุงูุฑุงู ุฏุงุฎู ุงููููุชููุฑ ูู ูุณุงุฑ /data
!udocker --allow-root run --volume=$(pwd):/data my_ai ls /data

Model
Thinking Thoughts

Expand to view model thoughts
chevron_right

ุทูุจ ููุชุงุฒ! ุจูุง ุฃูู ุชุนูู ุนูู ุงููุนุงูุฌ (CPU) ูุชุฑูุฏ ุดูุฆุงู ุฎูููุงู ูุณุฑูุนุงู ููุชุฌุงุฑุจุ ุฃูุถู ุฎูุงุฑ ูู ูู ูุณุฎุฉ Python Slim.

ุญุฌููุง ุตุบูุฑ ุฌุฏุงู (ุญูุงูู 40-50 ููุฌุงุจุงูุช) ููุงุฑูุฉ ุจู Ubuntu ุงููุงููุฉุ ูุชุฃุชู ูุน ุจุงูุซูู ุฌุงูุฒ.

ุฅููู ุงูุฎุทูุงุช ูุฅูุดุงุก ุงูุญุงููุฉุ ุงูุฏุฎูู ุฅูููุงุ ูุชุซุจูุช ููุชุจุฉ (ูุซูุงู requests) ูุชุฌุฑุจุชูุงุ ูู ูุฐุง ุจุงุณุชุฎุฏุงู udocker ูู Colab:
1. ุณุญุจ ุงูุตูุฑุฉ ูุฅูุดุงุก ุงูุญุงููุฉ

ุถุน ูุฐุง ุงูููุฏ ูู ุฎููุฉ ูุดุบูู ูุฑุฉ ูุงุญุฏุฉ:
code Bash

# ุณุญุจ ุตูุฑุฉ ุฎูููุฉ ุฌุฏุงู (Python Slim)
!udocker --allow-root pull python:3.9-slim

# ุฅูุดุงุก ุงูุญุงููุฉ ูุชุณููุชูุง "my_lab"
# (ูุณุชุฎุฏู create ููุญูุธ ุงูุชุบููุฑุงุช ุงูุชู ุณูููู ุจูุง ูุงุญูุงู)
!udocker --allow-root create --name=my_lab python:3.9-slim

2. ุชุซุจูุช ุงูููุชุจุฉ ุฏุงุฎู ุงูุญุงููุฉ

ุงูุขู ุณูููู ุจุชุดุบูู ุงูุญุงููุฉ ูุชุซุจูุช ููุชุจุฉ (ูุซูุงู numpy ุฃู requests).
ูุงุญุธ ุฃููุง ูุณุชุฎุฏู ุงุณู ุงูุญุงููุฉ my_lab ูููุณ ุงุณู ุงูุตูุฑุฉ.
code Bash

# ุชุซุจูุช ููุชุจุฉ numpy ุฏุงุฎู ุงูุญุงููุฉ
!udocker --allow-root run my_lab pip install numpy

3. ุชุฌุฑุจุฉ ุงูููุชุจุฉ (ุงุฎุชุจุงุฑ ุงูุชุซุจูุช)

ุงูุขู ุณูุดุบู ุงูุญุงููุฉ ูุฑุฉ ุฃุฎุฑู ูุชุดุบูู ููุฏ ุจุงูุซูู ูุณุชุฎุฏู ุงูููุชุจุฉ ุงูุชู ุซุจุชูุงูุง ููุชู.
code Bash

# ุชุดุบูู ููุฏ ุจุงูุซูู ุฏุงุฎู ุงูุญุงููุฉ
!udocker --allow-root run my_lab python -c "import numpy; print('Numpy Version inside container:', numpy.__version__)"

๐ก ููุงุญุธุฉ ูููุฉ ุฌุฏุงู (ููู ุชุนูู Colab ูุน ุงูุชูุงุนููุฉ):

ูู Google Colabุ ูุง ููููู "ุงูุฏุฎูู" ุฅูู ุงูุดุงุดุฉ ุงูุณูุฏุงุก (Shell) ูุงูุจูุงุก ูููุง ูููุชุงุจุฉ ุณุทุฑุงู ุจุณุทุฑ ููุง ูู ุฌูุงุฒู ุงูุดุฎุตู (ูุฃู Colab ููุตู ุงูุงุชุตุงู ุจุนุฏ ุงูุชูุงุก ุชูููุฐ ุงูุฎููุฉ).

ูุฐููุ ุงูุทุฑููุฉ ุงูุชู ูุชุจุชูุง ูู ุจุงูุฃุนูู (ุชุซุจูุช ูู ุฎููุฉุ ุซู ุชุดุบูู ูู ุฎููุฉ ุฃุฎุฑู) ูู ุงูุทุฑููุฉ ุงูุตุญูุญุฉุ ูุฃู udocker ูุญูุธ ุงูุชุบููุฑุงุช ุฏุงุฎู ุงููุฌูุฏ my_labุ ูุนูุฏูุง ุชุดุบู ุงูุฎููุฉ ุงูุชุงููุฉุ ุณุชุฌุฏ ุงูููุชุจุฉ ูุซุจุชุฉ ูุฌุงูุฒุฉ.

ุฅุฐุง ููุช ุชุฑูุฏ ุชุดุบูู ุนุฏุฉ ุฃูุงูุฑ ูุนุงู ูู ุณุทุฑ ูุงุญุฏุ ููููู ูุนู ุฐูู ููุฐุง:
code Bash

!udocker --allow-root run my_lab sh -c "pip install pandas && python -c 'import pandas; print(pandas.__version__)'"

Model
Thinking Thoughts

Expand to view model thoughts
chevron_right

ููุนุฑูุฉ ุงูุฅุตุฏุงุฑุงุช ุฏุงุฎู ุงููููุชููุฑ (ุงูุฐู ุณูููุงู my_lab ุณุงุจูุงู)ุ ูุณุชุฎุฏู ุงูุฃูุฑ run ูุชุจูุนุงู ุจุฃูุฑ ุงูุงุณุชุนูุงู.

ุฅููู ุงูุฃูุงูุฑ ุฌุงูุฒุฉ ูููุณุฎ ูุงููุตู ูู ูููุงุจ:
1. ููุนุฑูุฉ ุฅุตุฏุงุฑ ุจุงูุซูู (Python Version)
code Bash

!udocker --allow-root run my_lab python --version

2. ููุนุฑูุฉ ุฅุตุฏุงุฑ ููุชุจุฉ ูุนููุฉ (ุทุฑููุฉ pip)

ูุฐู ุงูุทุฑููุฉ ุชุนุฑุถ ุชูุงุตูู ุงูููุชุจุฉ (ุงูุฅุตุฏุงุฑุ ุงููููุนุ ุงูุฎ). ุงุณุชุจุฏู numpy ุจุงุณู ุงูููุชุจุฉ ุงูุชู ุชุฑูุฏูุง.
code Bash

!udocker --allow-root run my_lab pip show numpy

3. ููุนุฑูุฉ ุฅุตุฏุงุฑ ุงูููุชุจุฉ (ุทุฑููุฉ ุงูููุฏ - ุงูุฃุฏู)

ูุฐู ุงูุทุฑููุฉ ุฃูุถู ูุฃููุง ุชุชุฃูุฏ ุฃู ุงูููุชุจุฉ ุชุนูู ูุนูุงู ูุชููู ุจุทุจุงุนุฉ ุฑูู ุงูุฅุตุฏุงุฑ ููุท.
code Bash

!udocker --allow-root run my_lab python -c "import numpy; print(numpy.__version__)"

4. ุนุฑุถ ูู ุงูููุชุจุงุช ุงููุซุจุชุฉ

ุฅุฐุง ููุช ุชุฑูุฏ ูุงุฆูุฉ ุจูู ุดูุก ููุฌูุฏ ุฏุงุฎู ุงููููุชููุฑ:
code Bash

!udocker --allow-root run my_lab pip list

ููุงุญุธุฉ ูููุฉ: ุชุฃูุฏ ุฏุงุฆูุงู ูู ุงุณุชุฎุฏุงู ุงุณู ุงููููุชููุฑ (my_lab) ูููุณ ุงุณู ุงูุตูุฑุฉ (python:3.9-slim)ุ ูุฃูู ุฅุฐุง ุงุณุชุฎุฏูุช ุงุณู ุงูุตูุฑุฉุ ุณููุชุญ ูููุชููุฑ ุฌุฏูุฏุงู ูุงุฑุบุงู ููู ูุฌุฏ ุงูููุชุจุงุช ุงูุชู ุซุจุชูุง ุณุงุจูุงู.
Model
Thinking Thoughts

Expand to view model thoughts
chevron_right

ูุนูุ ูุฐู ุงูููุฑุฉ ููุชุงุฒุฉ ูุนูููุฉ ุฌุฏุงูุ ุฎุงุตุฉ ูู ุจูุฆุงุช ูุซู Google Colab ุฃู ุนูุฏ ุงูุฑุบุจุฉ ูู ุฏูุฌ ูู ุดูุก ูู ููุงู ูุงุญุฏ.

ุจูุง ุฃูู ุชุณุชุฎุฏู udocker (ุจูุงุกู ุนูู ุณูุงู ุญุฏูุซูุง ุงูุณุงุจู)ุ ูุงูุฃูุฑ ูุชุทูุจ "ุญููุฉ" ุจุณูุทุฉ ูุฃู ุงูุญุงููุฉ ูุง ุชุญุชูู ุนูู ูุฏูุฑ ุฎุฏูุงุช (Systemd) ูุชุดุบูู ุฃููุงูุง ูู ุงูุฎูููุฉ ุชููุงุฆูุงู.

ุฅููู ุงูุฎุทูุงุช ุงููุงููุฉ ูุชุซุจูุช Ollama ุฏุงุฎู ุญุงููุฉ AutoRAGุ ูุชุดุบูู ุงูุฎุงุฏูุ ูุชุญููู ุงูููุงุฐุฌุ ุซู ุฑุจุทูุง ุจู AutoRAG.
ุงูุฎุทูุฉ 1: ุงูุฏุฎูู ุฅูู ุงูุญุงููุฉ ูุชุซุจูุช Ollama

ุงูุชุฑุถ ุฃูู ุฃูุดุฃุช ุงูุญุงููุฉ ูุงุณููุง autorag_container. ุณูููู ุจุชูููุฐ ุณูุณูุฉ ุฃูุงูุฑ ูุชุซุจูุช ุฃููุงูุง.

ุงูุณุฎ ูุฐุง ุงูููุฏ ูู Colab:
code Bash

# 1. ุชุญุฏูุซ ุงูุญุฒู ูุชุซุจูุช curl (ุฃููุงูุง ูุญุชุงุฌู)
!udocker --allow-root run autorag_container apt-get update && apt-get install -y curl

# 2. ุชุญููู ูุชุซุจูุช ุฃููุงูุง (ูุฏููุงู ูุฃู ุณูุฑูุจุช ุงูุชุซุจูุช ุงูุชููุงุฆู ูุฏ ููุดู ูู udocker)
!udocker --allow-root run autorag_container bash -c "curl -L https://ollama.com/download/ollama-linux-amd64 -o /usr/bin/ollama && chmod +x /usr/bin/ollama"

ุงูุฎุทูุฉ 2: ุชุดุบูู ุงูุฎุงุฏู ูุชุญููู ุงูููุฏูู (ุงูุฎุฏุนุฉ ููุง) ๐ฅ

ุจูุง ุฃููุง ูู ุจูุฆุฉ ูุง ุชุฏุนู ุชุดุบูู ุงูุฎุฏูุงุช ูู ุงูุฎูููุฉ ุจุดูู ุฏุงุฆูุ ูุฌุจ ุนูููุง ุชุดุบูู ุฎุงุฏู ุฃููุงูุง (ollama serve) ููู ููุณ ุงูุณุทุฑ (ูู ุงูุฎูููุฉ) ูุทูุจ ููู ุชุญููู ุงูููุฏูู.

ุณูููู ุจุนูู ุณูุฑุจุช ุตุบูุฑ (setup_ollama.sh) ุฏุงุฎู ุงูุญุงููุฉ ููุดุบูู:
code Bash

# ุฅูุดุงุก ุณูุฑูุจุช ุฏุงุฎู ุงูุญุงููุฉ ูููู ุจุงููููุฉ
!udocker --allow-root run autorag_container bash -c 'cat <<EOF > start_ollama.sh
#!/bin/bash
# ุชุดุบูู ุฎุงุฏู ุฃููุงูุง ูู ุงูุฎูููุฉ
ollama serve &

# ุงูุงูุชุธุงุฑ ููููุงู ุญุชู ูุนูู ุงูุฎุงุฏู
echo "Waiting for Ollama to start..."
sleep 5

# ุชุญููู ุงูููุฏูู (ูุซูุงู mistral ุฃู llama3)
echo "Pulling Model..."
ollama pull mistral

# ุฅุจูุงุก ุงูุณูุฑูุจุช ูุนูู (ุงุฎุชูุงุฑู ุญุณุจ ุญุงุฌุชู) ุฃู ุงูุฎุฑูุฌ
echo "Model Pulled Successfully!"
EOF
chmod +x start_ollama.sh'

ุงูุขูุ ุดุบู ูุฐุง ุงูุณูุฑูุจุช ููุฑุฉ ูุงุญุฏุฉ ููููู ุจุงูุชุญููู:
code Bash

!udocker --allow-root run autorag_container ./start_ollama.sh

ุงูุฎุทูุฉ 3: ููู ุชุฌุนู AutoRAG ูุฑู Ollamaุ

ุงูุขู ุงูููุฏูู ููุฌูุฏ ุฏุงุฎู ุงูุญุงููุฉ. ุนูุฏ ุชุดุบูู AutoRAGุ ูุฌุจ ุฃู ุชุชุฃูุฏ ูู ุดูุฆูู:

    ุชุดุบูู ุฎุงุฏู ุฃููุงูุง ูุจู ุชุดุบูู AutoRAG:
    ูู ูู ูุฑุฉ ุชุฑูุฏ ุชุดุบูู AutoRAGุ ูุฌุจ ุฃู ูููู ุงูุฃูุฑ ูุงูุชุงูู (ูู ุณุทุฑ ูุงุญุฏ):
    code Bash

    !udocker --allow-root run autorag_container bash -c "ollama serve & python your_autorag_script.py"

    (ูุงุญุธ ุนูุงูุฉ & ุงูุชู ุชุฌุนู ุฃููุงูุง ูุนูู ูู ุงูุฎูููุฉ ุจูููุง ูุนูู ุณูุฑูุจุช ุจุงูุซูู ูู ุงูุฃูุงู).

    ุฅุนุฏุงุฏุงุช AutoRAG (ููู YAML):
    ุฏุงุฎู ููู ุฅุนุฏุงุฏุงุช AutoRAG (ุนุงุฏุฉ config.yaml)ุ ูุฌุจ ุฃู ุชุฎุชุงุฑ ููุน ุงูู LLM ููููู ollama ูุชุญุฏุฏ ุงูุฑุงุจุท ูุงูุงุณู.

    ูุซุงู ูุฅุนุฏุงุฏ ุงูู Config:
    code Yaml

    node_lines:
    - node_line_name: retrieve_node_line
      nodes:
        - node_type: retrieval
          strategy:
            metrics: [retrieval_f1, retrieval_recall]
          top_k: 3
          modules:
            - module_type: bm25
    - node_line_name: post_retrieve_node_line
      nodes:
        - node_type: generator
          strategy:
            metrics: [bleu, rouge, meteor]
          modules:
            - module_type: llama_index_llm
              llm: ollama
              model: mistral  # ููุณ ุงูุงุณู ุงูุฐู ุญููุชู
              base_url: http://localhost:11434  # ุงูุฑุงุจุท ุงูุฏุงุฎูู
              temperature: 0.1

ููุฎุต ุณุฑูุน ููุง ุณุชูุนูู:

    ุชุซุจุช curl ู ollama ุฏุงุฎู ุงูุญุงููุฉ.

    ุชุดุบู ollama serve & ุซู ollama pull model.

    ุนูุฏ ุชุดุบูู AutoRAGุ ุชุฏูุฌ ุฃูุฑ ุงูุชุดุบูู ููููู: ollama serve & autorag run ....

ุจูุฐู ุงูุทุฑููุฉุ ุงูุญุงููุฉ ุชุตุจุญ "ููุชููุฉ ุฐุงุชูุงู" (Self-contained)ุ ุจุฏุงุฎููุง ุงูููุฏ ูุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุนุงู.
info Google AI models may make mistakes, so double-check outputs.
Use Arrow Up and Arrow Down to select a turn, Enter to jump to it, and Escape to return to the chat.
google Grounding with Google Search

"""

